{"_id": "maxhumber_redframes/0", "text": "from __future__ import annotations\n\nfrom ..checks import _check_type\nfrom ..types import Column, Func, PandasDataFrame\n\n\ndef mutate(df: PandasDataFrame, over: dict[Column, Func]) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/0", "ground_truth": "    _check_type(over, dict)\n    df = df.copy()\n    for column, mutation in over.items():\n        df[column] = df.apply(mutation, axis=1)\n    return df  # type: ignore\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "mutate.py"], "context_start_lineno": 0, "lineno": 7, "function_name": "mutate", "line_no": 7}}
{"_id": "maxhumber_redframes/1", "text": "from __future__ import annotations\n\nfrom ..checks import _check_type\nfrom ..types import LazyColumns, PandasDataFrame\n\n\ndef drop(df: PandasDataFrame, columns: LazyColumns) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/1", "ground_truth": "    _check_type(columns, {list, str})\n    df = df.drop(columns, axis=1)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "drop.py"], "context_start_lineno": 0, "lineno": 7, "function_name": "drop", "line_no": 7}}
{"_id": "maxhumber_redframes/2", "text": "from ..checks import _check_type, _check_values\nfrom ..types import NewColumn, OldColumn, PandasDataFrame\n\n\ndef rename(df: PandasDataFrame, columns: dict[OldColumn, NewColumn]) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/2", "ground_truth": "    _check_type(columns, dict)\n    cv = columns.values()\n    _check_values(cv, str)\n    if len(set(cv)) != len(cv):\n        raise KeyError(\"columns must be unique\")\n    missing_keys = set(columns.keys()) - set(df.columns)\n    if missing_keys and len(missing_keys) == 1:\n        raise KeyError(f\"column key ({missing_keys}) is invalid\")\n    if missing_keys and len(missing_keys) > 1:\n        raise KeyError(f\"column keys ({missing_keys}) are invalid\")\n    df = df.rename(columns=columns)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "rename.py"], "context_start_lineno": 0, "lineno": 5, "function_name": "rename", "line_no": 5}}
{"_id": "maxhumber_redframes/3", "text": "import uuid\n\nfrom ..checks import _check_type\nfrom ..types import Column, Columns, PandasDataFrame\n\n\ndef split(\n    df: PandasDataFrame, column: Column, into: Columns, sep: str, drop: bool = True\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/3", "ground_truth": "    _check_type(column, str)\n    _check_type(into, list)\n    _check_type(sep, str)\n    _check_type(drop, bool)\n    if len(into) != len(set(into)):\n        raise KeyError(\"into keys must be unique\")\n    if (column in into) and (not drop):\n        raise KeyError(\"into keys must be unique\")\n    bad_keys = set(df.columns).difference(set([column])).intersection(set(into))\n    if bad_keys:\n        raise KeyError(\"into keys must be unique\")\n    columns = {uuid.uuid4().hex: col for col in into}\n    temp = list(columns.keys())\n    df = df.copy()\n    df[temp] = df[column].str.split(sep, expand=True)\n    if drop:\n        df = df.drop(column, axis=1)\n    df = df.rename(columns=columns)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "split.py"], "context_start_lineno": 0, "lineno": 9, "function_name": "split", "line_no": 9}}
{"_id": "maxhumber_redframes/4", "text": "from __future__ import annotations\n\nfrom ..checks import _check_keys, _check_type\nfrom ..types import LazyColumns, PandasDataFrame\n\n\ndef sort(\n    df: PandasDataFrame, columns: LazyColumns, descending: bool = False\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/4", "ground_truth": "    _check_type(columns, {list, str})\n    _check_type(descending, bool)\n    _check_keys(columns, df.columns)\n    df = df.sort_values(by=columns, ascending=not descending)\n    df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "sort.py"], "context_start_lineno": 0, "lineno": 9, "function_name": "sort", "line_no": 9}}
{"_id": "maxhumber_redframes/5", "text": "from __future__ import annotations\n\nfrom ..checks import _check_type\nfrom ..types import Column, PandasDataFrame, PandasGroupedFrame\n\n\ndef pack(\n    df: PandasDataFrame | PandasGroupedFrame, column: Column, sep: str\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/5", "ground_truth": "    _check_type(column, str)\n    _check_type(sep, str)\n    order = df.obj.columns if isinstance(df, PandasGroupedFrame) else df.columns  # type: ignore\n    df = df.agg(**{column: (column, lambda x: x.astype(str).str.cat(sep=sep))})  # type: ignore\n    df = df[[col for col in df.columns if col in order]]\n    df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "pack.py"], "context_start_lineno": 0, "lineno": 9, "function_name": "pack", "line_no": 9}}
{"_id": "maxhumber_redframes/6", "text": "from __future__ import annotations\n\nfrom ..checks import _check_type\nfrom ..types import Column, Func, PandasDataFrame, PandasGroupedFrame\n\n\ndef rollup(\n    df: PandasDataFrame | PandasGroupedFrame,\n    over: dict[Column, tuple[Column, Func]],\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/6", "ground_truth": "    _check_type(over, dict)\n    if isinstance(df, PandasGroupedFrame):\n        groups = set(df.grouper.names)  # type: ignore\n        keys = set(over.keys())\n        if groups.intersection(keys):\n            raise KeyError(\"unable to overwrite group keys\")\n        df = df.agg(**over)\n        df = df.reset_index(drop=True)\n    else:\n        df = df.agg(**over)  # type: ignore\n        df = df.T  # type: ignore\n        df = df.reset_index(drop=True)  # type: ignore\n        df = df.fillna(method=\"ffill\")  # type: ignore\n        df = df.fillna(method=\"bfill\")  # type: ignore\n        df = df.head(1)  # type: ignore\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "rollup.py"], "context_start_lineno": 0, "lineno": 10, "function_name": "rollup", "line_no": 10}}
{"_id": "maxhumber_redframes/7", "text": "import pandas as pd  # pyright: ignore[reportMissingImports]\n\nfrom ..types import PandasDataFrame\n\n\ndef append(top: PandasDataFrame, bottom: PandasDataFrame) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/7", "ground_truth": "    df = pd.concat([top, bottom])\n    df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "append.py"], "context_start_lineno": 0, "lineno": 6, "function_name": "append", "line_no": 6}}
{"_id": "maxhumber_redframes/8", "text": "from __future__ import annotations\n\nimport warnings\n\nfrom ..checks import _check_type\nfrom ..types import Column, Columns, PandasDataFrame\n\n\ndef combine(\n    df: PandasDataFrame, columns: Columns, into: Column, sep: str, drop: bool = True\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/8", "ground_truth": "    _check_type(columns, list)\n    _check_type(into, str)\n    _check_type(sep, str)\n    _check_type(drop, bool)\n    into_is_in_columns = into in columns\n    into_is_not_in_columns = not into_is_in_columns\n    into_is_in_df_columns = into in df.columns\n    if into_is_not_in_columns and into_is_in_df_columns:\n        message = f\"overwriting existing column '{into}'\"\n        warnings.warn(message)\n    df = df.copy()\n    new = df[columns].apply(lambda row: sep.join(row.values.astype(str)), axis=1)\n    if drop:\n        df = df.drop(columns, axis=1)\n    df[into] = new\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "combine.py"], "context_start_lineno": 0, "lineno": 11, "function_name": "combine", "line_no": 11}}
{"_id": "maxhumber_redframes/9", "text": "from ..checks import _check_type\nfrom ..types import Column, NewValue, OldValue, PandasDataFrame\n\n\ndef replace(\n    df: PandasDataFrame, over: dict[Column, dict[OldValue, NewValue]]\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/9", "ground_truth": "    _check_type(over, dict)\n    bad_columns = list(set(over.keys()) - set(df.columns))\n    if bad_columns and len(bad_columns) == 1:\n        raise KeyError(f\"column key: {bad_columns} is invalid\")\n    if bad_columns and len(bad_columns) > 1:\n        raise KeyError(f\"column keys: {bad_columns} are invalid\")\n    df = df.replace(over)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "replace.py"], "context_start_lineno": 0, "lineno": 7, "function_name": "replace", "line_no": 7}}
{"_id": "maxhumber_redframes/10", "text": "from __future__ import annotations\n\nfrom ..checks import _check_type\nfrom ..types import LazyColumns, PandasDataFrame\n\n\ndef denix(df: PandasDataFrame, columns: LazyColumns | None = None) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/10", "ground_truth": "    _check_type(columns, {list, str, None})\n    columns = [columns] if isinstance(columns, str) else columns\n    if isinstance(columns, list):\n        bad_keys = set(columns).difference(df.columns)\n        if bad_keys:\n            if len(bad_keys) == 1:\n                message = f\"columns argument contains invalid key {bad_keys}\"\n            else:\n                message = f\"columns argument contains invalid keys {bad_keys}\"\n            raise KeyError(message)\n    df = df.dropna(subset=columns)\n    df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "denix.py"], "context_start_lineno": 0, "lineno": 7, "function_name": "denix", "line_no": 7}}
{"_id": "maxhumber_redframes/11", "text": "from __future__ import annotations\n\nfrom ..checks import _check_keys, _check_type\nfrom ..types import LazyColumns, PandasDataFrame\n\n\ndef dedupe(df: PandasDataFrame, columns: LazyColumns | None = None) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/11", "ground_truth": "    _check_type(columns, {list, str, None})\n    _check_keys(columns, df.columns)\n    df = df.drop_duplicates(subset=columns, keep=\"first\")\n    df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "dedupe.py"], "context_start_lineno": 0, "lineno": 7, "function_name": "dedupe", "line_no": 7}}
{"_id": "maxhumber_redframes/12", "text": "from __future__ import annotations\n\nimport warnings\n\nfrom ..checks import _check_type\nfrom ..types import Column, PandasDataFrame, PandasGroupedFrame\n\n\ndef accumulate(\n    df: PandasDataFrame | PandasGroupedFrame, column: Column, into: Column\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/12", "ground_truth": "    _check_type(column, str)\n    _check_type(into, str)\n    if isinstance(df, PandasDataFrame):\n        into_is_not_column = into != column\n        into_is_in_df_columns = into in df.columns\n        if into_is_not_column and into_is_in_df_columns:\n            message = f\"overwriting existing column '{into}'\"\n            warnings.warn(message)\n        df = df.copy()\n    result = df[column].cumsum()\n    if isinstance(df, PandasGroupedFrame):\n        df = df.obj.copy()  # type: ignore\n    df[into] = result  # type: ignore\n    return df  # type: ignore\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "accumulate.py"], "context_start_lineno": 0, "lineno": 11, "function_name": "accumulate", "line_no": 11}}
{"_id": "maxhumber_redframes/13", "text": "from __future__ import annotations\n\nimport pandas as pd  # pyright: ignore[reportMissingImports]\n\nfrom ..checks import _check_type\nfrom ..types import PandasDataFrame\n\n\ndef cross(\n    lhs: PandasDataFrame,\n    rhs: PandasDataFrame,\n    postfix: tuple[str, str] = (\"_lhs\", \"_rhs\"),\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/13", "ground_truth": "    _check_type(postfix, tuple)\n    df = pd.merge(lhs, rhs, how=\"cross\", suffixes=postfix)\n    df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "cross.py"], "context_start_lineno": 0, "lineno": 13, "function_name": "cross", "line_no": 13}}
{"_id": "maxhumber_redframes/14", "text": "from __future__ import annotations\n\nfrom ..checks import _check_type\nfrom ..types import PandasDataFrame\n\n\ndef sample(\n    df: PandasDataFrame, rows: int | float, seed: int | None = None\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/14", "ground_truth": "    _check_type(rows, {int, float})\n    if rows >= 1:\n        if isinstance(rows, float):\n            raise ValueError(\"must be int if > 1\")\n        df = df.sample(rows, random_state=seed)\n    elif 0 < rows < 1:\n        df = df.sample(frac=rows, random_state=seed)\n    else:\n        raise ValueError(\"must be > 0\")\n    df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "sample.py"], "context_start_lineno": 0, "lineno": 9, "function_name": "sample", "line_no": 9}}
{"_id": "maxhumber_redframes/15", "text": "from __future__ import annotations\n\nfrom ..checks import _check_type\nfrom ..types import PandasDataFrame\n\n\ndef shuffle(df: PandasDataFrame, seed: int | None = None) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/15", "ground_truth": "    _check_type(seed, {int, None})\n    df = df.sample(frac=1, random_state=seed)\n    df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "shuffle.py"], "context_start_lineno": 0, "lineno": 7, "function_name": "shuffle", "line_no": 7}}
{"_id": "maxhumber_redframes/16", "text": "from __future__ import annotations\n\nfrom ..checks import _check_type\nfrom ..types import Column, PandasDataFrame\n\n\ndef unpack(df: PandasDataFrame, column: Column, sep: str) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/16", "ground_truth": "    _check_type(column, str)\n    _check_type(sep, str)\n    df = df.assign(**{column: df[column].str.split(sep)})\n    df = df.explode(column)\n    df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "unpack.py"], "context_start_lineno": 0, "lineno": 7, "function_name": "unpack", "line_no": 7}}
{"_id": "maxhumber_redframes/17", "text": "from __future__ import annotations\n\nimport warnings\n\nfrom ..checks import _check_type\nfrom ..types import Column, PandasDataFrame, PandasGroupedFrame\n\n\ndef rank(\n    df: PandasDataFrame | PandasGroupedFrame,\n    column: Column,\n    into: Column,\n    descending: bool = False,\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/17", "ground_truth": "    _check_type(column, str)\n    _check_type(into, str)\n    _check_type(descending, bool)\n    if isinstance(df, PandasDataFrame):\n        into_is_not_column = into != column\n        into_is_in_df_columns = into in df.columns\n        if into_is_not_column and into_is_in_df_columns:\n            message = f\"overwriting existing column '{into}'\"\n            warnings.warn(message)\n        df = df.copy()\n    result = df[column].rank(method=\"dense\", ascending=not descending)\n    if isinstance(df, PandasGroupedFrame):\n        df = df.obj.copy()  # type: ignore\n    df[into] = result  # type: ignore\n    return df  # type: ignore\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "rank.py"], "context_start_lineno": 0, "lineno": 14, "function_name": "rank", "line_no": 14}}
{"_id": "maxhumber_redframes/18", "text": "from __future__ import annotations\n\nfrom ..checks import _check_type\nfrom ..types import Direction, LazyColumns, PandasDataFrame, Value\n\n\ndef fill(\n    df: PandasDataFrame,\n    columns: LazyColumns | None = None,\n    direction: Direction | None = None,\n    constant: Value | None = None,\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/18", "ground_truth": "    _check_type(columns, {list, str, None})\n    _check_type(direction, {str, None})\n    columns = [columns] if isinstance(columns, str) else columns\n    if (direction != None) and (constant != None):\n        raise ValueError(\"either direction OR constant must be None\")\n    if (direction == None) and (constant == None):\n        raise ValueError(\"either direction OR constant must not be None\")\n    if direction != None:\n        if not (direction in [\"down\", \"up\"]):\n            raise ValueError(\"must be one of {'down', 'up'}\")\n        method = {\"down\": \"ffill\", \"up\": \"bfill\"}.get(direction)\n        value = None\n    if constant != None:\n        value = constant\n        method = None\n    df = df.copy()\n    if columns:\n        df[columns] = df[columns].fillna(value=value, method=method)  # type: ignore\n    else:\n        df = df.fillna(value=value, method=method)  # type: ignore\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "fill.py"], "context_start_lineno": 0, "lineno": 12, "function_name": "fill", "line_no": 12}}
{"_id": "maxhumber_redframes/19", "text": "import uuid\n\nimport pandas as pd  # pyright: ignore[reportMissingImports]\n\nfrom ..checks import _check_type\nfrom ..types import Column, PandasDataFrame\n\n\ndef spread(df: PandasDataFrame, column: Column, using: Column) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/19", "ground_truth": "    _check_type(column, str)\n    _check_type(using, str)\n    if column == using:\n        raise KeyError(\"column and using must be unique\")\n    original_shape = df.shape[1]\n    if original_shape == 2:\n        temp = uuid.uuid4().hex\n        df[temp] = df.groupby(column).cumcount()\n    index = [col for col in df.columns if col not in [column, using]]\n    df = pd.pivot_table(df, index=index, columns=[column], values=[using], aggfunc=\"first\")  # type: ignore\n    df.columns = [col for col in df.columns.get_level_values(1)]  # type: ignore\n    df = df.reset_index().rename_axis(None, axis=0)\n    if original_shape == 2:\n        df = df.drop(temp, axis=1)  # type: ignore\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "spread.py"], "context_start_lineno": 0, "lineno": 9, "function_name": "spread", "line_no": 9}}
{"_id": "maxhumber_redframes/20", "text": "from __future__ import annotations\n\nimport warnings\n\nimport pandas as pd  # pyright: ignore[reportMissingImports]\n\nfrom ..checks import _check_type\nfrom ..types import Column, Columns, LazyColumns, PandasDataFrame, PandasGroupedFrame\n\n\ndef _melt(\n    df: PandasDataFrame,\n    cols_to_keep: list[str],\n    cols_to_gather: list[str],\n    into: tuple[str, str],\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/20", "ground_truth": "    df = pd.melt(\n        df,\n        id_vars=cols_to_keep,\n        value_vars=cols_to_gather,\n        var_name=into[0],\n        value_name=into[1],\n    )\n    df = df.dropna(subset=into[1])  # type: ignore\n    df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "gather.py"], "context_start_lineno": 0, "lineno": 16, "function_name": "_melt", "line_no": 16}}
{"_id": "maxhumber_redframes/21", "text": "from __future__ import annotations\n\nimport warnings\n\nimport pandas as pd  # pyright: ignore[reportMissingImports]\n\nfrom ..checks import _check_type\nfrom ..types import Column, Columns, LazyColumns, PandasDataFrame, PandasGroupedFrame\n\n\ndef _melt(\n    df: PandasDataFrame,\n    cols_to_keep: list[str],\n    cols_to_gather: list[str],\n    into: tuple[str, str],\n) -> PandasDataFrame:\n    df = pd.melt(\n        df,\n        id_vars=cols_to_keep,\n        value_vars=cols_to_gather,\n        var_name=into[0],\n        value_name=into[1],\n    )\n    df = df.dropna(subset=into[1])  # type: ignore\n    df = df.reset_index(drop=True)\n    return df\n\n\ndef _grouped_melt(df: PandasGroupedFrame, into: tuple[str, str]) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/21", "ground_truth": "    cols_to_keep = df.grouper.names  # type: ignore\n    cols_to_gather = [col for col in df.obj.columns if col not in cols_to_keep]  # type: ignore\n    df = _melt(df.obj, cols_to_keep, cols_to_gather, into)  # type: ignore\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "gather.py"], "context_start_lineno": 0, "lineno": 29, "function_name": "_grouped_melt", "line_no": 29}}
{"_id": "maxhumber_redframes/22", "text": "from __future__ import annotations\n\nimport pandas as pd  # pyright: ignore[reportMissingImports]\n\nfrom ..checks import _check_type\nfrom ..types import Join, LazyColumns, PandasDataFrame\n\n\ndef join(\n    lhs: PandasDataFrame,\n    rhs: PandasDataFrame,\n    on: LazyColumns,\n    how: Join = \"left\",\n    postfix: tuple[str, str] = (\"_lhs\", \"_rhs\"),\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/22", "ground_truth": "    _check_type(on, {list, str})\n    _check_type(how, str)\n    _check_type(postfix, tuple)\n    if not how in [\"left\", \"right\", \"inner\", \"full\"]:\n        message = (\n            \"on argument is invalid, must be one of {'left', 'right', 'inner', 'full'}\"\n        )\n        raise ValueError(message)\n    how = \"outer\" if (how == \"full\") else how  # type: ignore\n    df = pd.merge(lhs, rhs, on=on, how=how, suffixes=postfix)\n    df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "join.py"], "context_start_lineno": 0, "lineno": 15, "function_name": "join", "line_no": 15}}
{"_id": "maxhumber_redframes/23", "text": "from ..types import Func, PandasDataFrame\n\n\ndef filter(df: PandasDataFrame, func: Func) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/23", "ground_truth": "    if not callable(func):\n        raise TypeError(\"must be Func\")\n    df = df.loc[func]  # type: ignore\n    df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "filter.py"], "context_start_lineno": 0, "lineno": 4, "function_name": "filter", "line_no": 4}}
{"_id": "maxhumber_redframes/24", "text": "from __future__ import annotations\n\nfrom ..checks import _check_type\nfrom ..types import PandasDataFrame, PandasGroupedFrame\n\n\ndef take(\n    df: PandasDataFrame | PandasGroupedFrame, rows: int = 1, **kwargs\n) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/24", "ground_truth": "    if kwargs:  # compatibility: sklearn / train_test_split\n        df = df.take(rows, **kwargs)  # type: ignore\n        df = df.reset_index(drop=True)\n        return df\n    _check_type(rows, int)\n    if isinstance(df, PandasDataFrame):\n        if rows > df.shape[0]:\n            raise ValueError(\"rows argument is invalid, exceeds total size\")\n    if rows == 0:\n        raise ValueError(\"rows argument is invalid, must not be 0\")\n    if rows <= -1:\n        df = df.tail(rows * -1)\n    else:\n        df = df.head(rows)\n    if isinstance(df, PandasGroupedFrame):\n        df = df.reset_index()\n    else:\n        df = df.reset_index(drop=True)\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "take.py"], "context_start_lineno": 0, "lineno": 9, "function_name": "take", "line_no": 9}}
{"_id": "maxhumber_redframes/25", "text": "from __future__ import annotations\n\nfrom ..checks import _check_type\nfrom ..types import LazyColumns, PandasDataFrame, PandasGroupedFrame\n\n\ndef group(df: PandasDataFrame, by: LazyColumns) -> PandasGroupedFrame:", "metadata": {"task_id": "maxhumber_redframes/25", "ground_truth": "    _check_type(by, {list, str})\n    gdf = df.groupby(by, as_index=False, sort=False)\n    return gdf\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "group.py"], "context_start_lineno": 0, "lineno": 7, "function_name": "group", "line_no": 7}}
{"_id": "maxhumber_redframes/26", "text": "import pandas as pd  # pyright: ignore[reportMissingImports]\n\nfrom ..checks import _check_type\nfrom ..types import LazyColumns, PandasDataFrame\n\n\ndef select(df: PandasDataFrame, columns: LazyColumns) -> PandasDataFrame:", "metadata": {"task_id": "maxhumber_redframes/26", "ground_truth": "    _check_type(columns, {list, str})\n    columns = [columns] if isinstance(columns, str) else columns\n    if len(set(columns)) != len(columns):\n        raise KeyError(f\"column keys must be unique\")\n    bad_columns = list(set(columns) - set(df.columns))\n    if bad_columns and len(bad_columns) == 1:\n        raise KeyError(f\"column key: {bad_columns} is invalid\")\n    if bad_columns and len(bad_columns) > 1:\n        raise KeyError(f\"column keys: {bad_columns} are invalid\")\n    df = df[columns]\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "verbs", "select.py"], "context_start_lineno": 0, "lineno": 7, "function_name": "select", "line_no": 7}}
{"_id": "maxhumber_redframes/27", "text": "from ..checks import _check_file, _check_type\nfrom ..core import DataFrame\n\n\ndef save(df: DataFrame, path: str, **kwargs) -> None:\n    \"\"\"Save a rf.DataFrame to a csv file (opposite of `load`)\n\n    Example:\n\n    ```python\n    rf.save(df, \"example.csv\")\n    ```\n    \"\"\"", "metadata": {"task_id": "maxhumber_redframes/27", "ground_truth": "    _check_type(df, DataFrame)\n    _check_type(path, str)\n    _check_file(path)\n    df._data.to_csv(path, index=False, **kwargs)\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "io", "save.py"], "context_start_lineno": 0, "lineno": 13, "function_name": "save", "line_no": 13}}
{"_id": "maxhumber_redframes/28", "text": "import pandas as pd  # pyright: ignore[reportMissingImports]\n\nfrom redframes.types import PandasDataFrame\n\nfrom ..checks import _check_columns, _check_file, _check_index, _check_type\nfrom ..core import DataFrame, _wrap\n\n\ndef load(path: str, **kwargs) -> DataFrame:\n    \"\"\"Load a csv file into a rf.DataFrame (opposite of `save`)\n\n    Example:\n\n    ```python\n    df = rf.load(\"example.csv\")\n    ```\n    \"\"\"", "metadata": {"task_id": "maxhumber_redframes/28", "ground_truth": "    _check_type(path, str)\n    _check_file(path)\n    data: PandasDataFrame = pd.read_csv(path, **kwargs)  # type: ignore\n    _check_index(data)\n    _check_columns(data)\n    return _wrap(data)\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "io", "load.py"], "context_start_lineno": 0, "lineno": 17, "function_name": "load", "line_no": 17}}
{"_id": "maxhumber_redframes/29", "text": "from __future__ import annotations\n\nfrom ..checks import _check_columns, _check_index, _check_type\nfrom ..core import DataFrame\nfrom ..types import PandasDataFrame\n\n\ndef unwrap(rdf: DataFrame) -> PandasDataFrame:\n    \"\"\"Convert a rf.DataFrame into a pd.DataFrame (opposite of `wrap`)\n\n    Example:\n\n    ```python\n    rdf = rf.DataFrame({\"foo\": range(10)})\n    pdf = rf.unwrap(rdf)\n    ```\n    \"\"\"\n    _check_type(rdf, DataFrame)\n    return rdf._data.copy()\n\n\ndef wrap(pdf: PandasDataFrame) -> DataFrame:\n    \"\"\"Convert a pd.DataFrame into a rf.DataFrame (opposite of `unwrap`)\n\n    Example:\n\n    ```python\n    pdf = pd.DataFrame({\"foo\": range(10)})\n    rdf = rf.wrap(pdf)\n    ```\n    \"\"\"", "metadata": {"task_id": "maxhumber_redframes/29", "ground_truth": "    _check_type(pdf, PandasDataFrame)\n    _check_index(pdf)\n    _check_columns(pdf)\n    rdf = DataFrame()\n    rdf._data = pdf.copy()\n    return rdf\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "io", "convert.py"], "context_start_lineno": 0, "lineno": 31, "function_name": "wrap", "line_no": 31}}
{"_id": "maxhumber_redframes/30", "text": "from __future__ import annotations\n\nimport pprint\nimport warnings\n\nfrom .checks import _check_type\nfrom .types import (\n    Any,\n    Column,\n    Columns,\n    DateTime,\n    Direction,\n    Func,\n    Join,\n    LazyColumns,\n    NewColumn,\n    NewValue,\n    NumpyArray,\n    NumpyType,\n    OldColumn,\n    OldValue,\n    PandasDataFrame,\n    PandasGroupedFrame,\n    Value,\n    Values,\n)\nfrom .verbs import (\n    accumulate,\n    append,\n    combine,\n    cross,\n    dedupe,\n    denix,\n    drop,\n    fill,\n    filter,\n    gather,\n    group,\n    join,\n    mutate,\n    pack,\n    rank,\n    rename,\n    replace,\n    rollup,\n    sample,\n    select,\n    shuffle,\n    sort,\n    split,\n    spread,\n    take,\n    unpack,\n)\n\n\ndef _wrap(data: PandasDataFrame) -> DataFrame:\n    \"\"\"Unsafe version of redframes.io.wrap()\"\"\"", "metadata": {"task_id": "maxhumber_redframes/30", "ground_truth": "    df = DataFrame()\n    df._data = data\n    return df\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "core.py"], "context_start_lineno": 0, "lineno": 58, "function_name": "_wrap", "line_no": 58}}
{"_id": "maxhumber_redframes/31", "text": "        |     1 |\n        |     2 |\n        |     3 |\n        |     4 |\n\n        ```python\n        df.accumulate(\"foo\", into=\"cumsum\")\n        ```\n        |   foo |   cumsum |\n        |------:|---------:|\n        |     1 |        1 |\n        |     2 |        3 |\n        |     3 |        6 |\n        |     4 |       10 |\n        \"\"\"\n        return _wrap(accumulate(self._data, column, into))\n\n    def gather(\n        self,\n        columns: Columns | None = None,\n        beside: LazyColumns | None = None,\n        into: tuple[Column, Column] = (\"variable\", \"value\"),\n    ):\n        \"\"\"Gather columns into rows (opposite of spread)\n\n        Examples:\n\n        ```python\n        df = rf.DataFrame({\n            \"foo\": [1, 2, 1, 2],\n            \"bar\": [\"A\", \"B\", \"C\", \"D\"],\n            \"baz\": [\"!\", \"@\", \"#\", \"$\"],\n            \"jaz\": range(4)\n        })\n        ```\n        |   foo | bar   | baz   |   jaz |\n        |------:|:------|:------|------:|\n        |     1 | A     | !     |     0 |\n        |     2 | B     | @     |     1 |\n        |     1 | C     | #     |     2 |\n        |     2 | D     | $     |     3 |\n\n        All columns:\n\n        ```python\n        df.gather()\n        ```\n        | variable   | value   |\n        |:-----------|:--------|\n        | foo        | 1       |\n        | foo        | 2       |\n        | foo        | 1       |\n        | foo        | 2       |\n        | bar        | A       |\n        | bar        | B       |\n        | bar        | C       |\n        | bar        | D       |\n        | baz        | !       |\n        | baz        | @       |\n        | baz        | #       |\n        | baz        | $       |\n        | jaz        | 0       |\n        | jaz        | 1       |\n        | jaz        | 2       |\n        | jaz        | 3       |\n\n        Multiple columns:\n\n        ```python\n        df.gather([\"foo\", \"bar\"], into=(\"var\", \"val\"))\n        ```\n        | baz   |   jaz | var   | val   |\n        |:------|------:|:------|:------|\n        | !     |     0 | foo   | 1     |\n        | @     |     1 | foo   | 2     |\n        | #     |     2 | foo   | 1     |\n        | $     |     3 | foo   | 2     |\n        | !     |     0 | bar   | A     |\n        | @     |     1 | bar   | B     |\n        | #     |     2 | bar   | C     |\n        | $     |     3 | bar   | D     |\n\n        All columns beside:\n\n        ```python\n        df.group([\"foo\", \"bar\"]).gather(into=(\"variable\", \"value\"))\n        ```\n        |   foo | bar   | variable   | value   |\n        |------:|:------|:-----------|:--------|\n        |     1 | A     | baz        | !       |\n        |     2 | B     | baz        | @       |\n        |     1 | C     | baz        | #       |\n        |     2 | D     | baz        | $       |\n        |     1 | A     | jaz        | 0       |\n        |     2 | B     | jaz        | 1       |\n        |     1 | C     | jaz        | 2       |\n        |     2 | D     | jaz        | 3       |\n        \"\"\"\n        return _wrap(gather(self._data, columns, beside, into))\n\n    def pack(self, column: Column, sep: str) -> DataFrame:\n        \"\"\"Collate and concatenate row values for a target column (opposite of unpack)\n\n        Examples:\n\n        ```python\n        df = rf.DataFrame({\n            \"foo\": [\"A\", \"A\", \"B\", \"A\", \"B\", \"C\"],\n            \"bar\": [1, 2, 3, 4, 5, 6]\n        })\n        ```\n        | foo   |   bar |\n        |:------|------:|\n        | A     |     1 |\n        | A     |     2 |\n        | B     |     3 |\n        | A     |     4 |\n        | B     |     5 |\n        | C     |     6 |\n\n        Pack all rows:\n\n        ```python\n        df.pack(\"foo\", sep=\"+\")\n        ```\n        | foo         |\n        |:------------|\n        | A+A+B+A+B+C |\n\n        Pack rows by Group:\n\n        ```python\n        df.group(\"foo\").pack(\"bar\", sep=\"|\")\n        ```\n        | foo   | bar   |\n        |:------|:------|\n        | A     | 1|2|4 |\n        | B     | 3|5   |\n        | C     | 6     |\n        \"\"\"\n        return _wrap(pack(self._data, column, sep))\n\n    def rank(\n        self,\n        column: Column,\n        into: Column,\n        descending: bool = False,\n    ) -> DataFrame:\n        \"\"\"Rank order values in a column\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [2, 3, 3, 99, 1000, 1, -6, 4]})\n        ```\n        |   foo |\n        |------:|\n        |     2 |\n        |     3 |\n        |     3 |\n        |    99 |\n        |  1000 |\n        |     1 |\n        |    -6 |\n        |     4 |\n\n        ```python\n        df.rank(\"foo\", into=\"rank\", descending=True)\n        ```\n        |   foo |   rank |\n        |------:|-------:|\n        |     2 |      5 |\n        |     3 |      4 |\n        |     3 |      4 |\n        |    99 |      2 |\n        |  1000 |      1 |\n        |     1 |      6 |\n        |    -6 |      7 |\n        |     4 |      3 |\n        \"\"\"\n        return _wrap(rank(self._data, column, into, descending))\n\n    def rollup(self, over: dict[Column, tuple[Column, Func]]) -> DataFrame:\n        \"\"\"Apply summary functions and/or statistics to target columns\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2, 3, 4, 5], \"bar\": [99, 100, 1, -5, 2]})\n        ```\n        |   foo |   bar |\n        |------:|------:|\n        |     1 |    99 |\n        |     2 |   100 |\n        |     3 |     1 |\n        |     4 |    -5 |\n        |     5 |     2 |\n\n        ```python\n        df.rollup({\n            \"fcount\": (\"foo\", rf.stat.count),\n            \"fmean\": (\"foo\", rf.stat.mean),\n            \"fsum\": (\"foo\", rf.stat.sum),\n            \"fmax\": (\"foo\", rf.stat.max),\n            \"bmedian\": (\"bar\", rf.stat.median),\n            \"bmin\": (\"bar\", rf.stat.min),\n            \"bstd\": (\"bar\", rf.stat.std)\n        })\n        ```\n        |   fcount |   fmean |   fsum |   fmax |   bmedian |   bmin |   bstd |\n        |---------:|--------:|-------:|-------:|----------:|-------:|-------:|\n        |        5 |       3 |     15 |      5 |         2 |     -5 |  54.93 |\n        \"\"\"\n        return _wrap(rollup(self._data, over))\n\n    def summarize(self, over: dict[Column, tuple[Column, Func]]) -> DataFrame:", "metadata": {"task_id": "maxhumber_redframes/31", "ground_truth": "        message = \"Marked for removal, please use `rollup` instead\"\n        warnings.warn(message, FutureWarning)\n        return self.rollup(over)\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "core.py"], "context_start_lineno": 142, "lineno": 358, "function_name": "summarize", "line_no": 358}}
{"_id": "maxhumber_redframes/32", "text": "az   |   jaz |\n        |------:|:------|:------|------:|\n        |     1 | A     | !     |     0 |\n        |     2 | B     | @     |     1 |\n        |     1 | C     | #     |     2 |\n        |     2 | D     | $     |     3 |\n\n        All columns:\n\n        ```python\n        df.gather()\n        ```\n        | variable   | value   |\n        |:-----------|:--------|\n        | foo        | 1       |\n        | foo        | 2       |\n        | foo        | 1       |\n        | foo        | 2       |\n        | bar        | A       |\n        | bar        | B       |\n        | bar        | C       |\n        | bar        | D       |\n        | baz        | !       |\n        | baz        | @       |\n        | baz        | #       |\n        | baz        | $       |\n        | jaz        | 0       |\n        | jaz        | 1       |\n        | jaz        | 2       |\n        | jaz        | 3       |\n\n        Multiple columns:\n\n        ```python\n        df.gather([\"foo\", \"bar\"], into=(\"var\", \"val\"))\n        ```\n        | baz   |   jaz | var   | val   |\n        |:------|------:|:------|:------|\n        | !     |     0 | foo   | 1     |\n        | @     |     1 | foo   | 2     |\n        | #     |     2 | foo   | 1     |\n        | $     |     3 | foo   | 2     |\n        | !     |     0 | bar   | A     |\n        | @     |     1 | bar   | B     |\n        | #     |     2 | bar   | C     |\n        | $     |     3 | bar   | D     |\n\n        All columns beside:\n\n        ```python\n        df.group([\"foo\", \"bar\"]).gather(into=(\"variable\", \"value\"))\n        ```\n        |   foo | bar   | variable   | value   |\n        |------:|:------|:-----------|:--------|\n        |     1 | A     | baz        | !       |\n        |     2 | B     | baz        | @       |\n        |     1 | C     | baz        | #       |\n        |     2 | D     | baz        | $       |\n        |     1 | A     | jaz        | 0       |\n        |     2 | B     | jaz        | 1       |\n        |     1 | C     | jaz        | 2       |\n        |     2 | D     | jaz        | 3       |\n        \"\"\"\n        return _wrap(gather(self._data, columns, beside, into))\n\n    def pack(self, column: Column, sep: str) -> DataFrame:\n        \"\"\"Collate and concatenate row values for a target column (opposite of unpack)\n\n        Examples:\n\n        ```python\n        df = rf.DataFrame({\n            \"foo\": [\"A\", \"A\", \"B\", \"A\", \"B\", \"C\"],\n            \"bar\": [1, 2, 3, 4, 5, 6]\n        })\n        ```\n        | foo   |   bar |\n        |:------|------:|\n        | A     |     1 |\n        | A     |     2 |\n        | B     |     3 |\n        | A     |     4 |\n        | B     |     5 |\n        | C     |     6 |\n\n        Pack all rows:\n\n        ```python\n        df.pack(\"foo\", sep=\"+\")\n        ```\n        | foo         |\n        |:------------|\n        | A+A+B+A+B+C |\n\n        Pack rows by Group:\n\n        ```python\n        df.group(\"foo\").pack(\"bar\", sep=\"|\")\n        ```\n        | foo   | bar   |\n        |:------|:------|\n        | A     | 1|2|4 |\n        | B     | 3|5   |\n        | C     | 6     |\n        \"\"\"\n        return _wrap(pack(self._data, column, sep))\n\n    def rank(\n        self,\n        column: Column,\n        into: Column,\n        descending: bool = False,\n    ) -> DataFrame:\n        \"\"\"Rank order values in a column\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [2, 3, 3, 99, 1000, 1, -6, 4]})\n        ```\n        |   foo |\n        |------:|\n        |     2 |\n        |     3 |\n        |     3 |\n        |    99 |\n        |  1000 |\n        |     1 |\n        |    -6 |\n        |     4 |\n\n        ```python\n        df.rank(\"foo\", into=\"rank\", descending=True)\n        ```\n        |   foo |   rank |\n        |------:|-------:|\n        |     2 |      5 |\n        |     3 |      4 |\n        |     3 |      4 |\n        |    99 |      2 |\n        |  1000 |      1 |\n        |     1 |      6 |\n        |    -6 |      7 |\n        |     4 |      3 |\n        \"\"\"\n        return _wrap(rank(self._data, column, into, descending))\n\n    def rollup(self, over: dict[Column, tuple[Column, Func]]) -> DataFrame:\n        \"\"\"Apply summary functions and/or statistics to target columns\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2, 3, 4, 5], \"bar\": [99, 100, 1, -5, 2]})\n        ```\n        |   foo |   bar |\n        |------:|------:|\n        |     1 |    99 |\n        |     2 |   100 |\n        |     3 |     1 |\n        |     4 |    -5 |\n        |     5 |     2 |\n\n        ```python\n        df.rollup({\n            \"fcount\": (\"foo\", rf.stat.count),\n            \"fmean\": (\"foo\", rf.stat.mean),\n            \"fsum\": (\"foo\", rf.stat.sum),\n            \"fmax\": (\"foo\", rf.stat.max),\n            \"bmedian\": (\"bar\", rf.stat.median),\n            \"bmin\": (\"bar\", rf.stat.min),\n            \"bstd\": (\"bar\", rf.stat.std)\n        })\n        ```\n        |   fcount |   fmean |   fsum |   fmax |   bmedian |   bmin |   bstd |\n        |---------:|--------:|-------:|-------:|----------:|-------:|-------:|\n        |        5 |       3 |     15 |      5 |         2 |     -5 |  54.93 |\n        \"\"\"\n        return _wrap(rollup(self._data, over))\n\n    def summarize(self, over: dict[Column, tuple[Column, Func]]) -> DataFrame:\n        message = \"Marked for removal, please use `rollup` instead\"\n        warnings.warn(message, FutureWarning)\n        return self.rollup(over)\n\n\nclass GroupedFrame(_CommonMixin):\n    \"\"\"GroupedFrame compatible with: `accumulate`, `gather`, `pack`, `rank`, `rollup`, `take`\"\"\"\n\n    def __repr__(self) -> str:\n        return self._data.obj.__repr__()  # type: ignore\n\n    def _repr_html_(self) -> str:\n        return self._data.obj.to_html(index=True)  # type: ignore\n\n\nclass DataFrame(_CommonMixin, _InterchangeMixin):\n    def __init__(self, data: dict[Column, Values] | None = None) -> None:\n        \"\"\"Initialize a DataFrame with a standard dictionary\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        ```\n        |   foo | bar   |\n        |------:|:------|\n        |     1 | A     |\n        |     2 | B     |\n        \"\"\"", "metadata": {"task_id": "maxhumber_redframes/32", "ground_truth": "        _check_type(data, {dict, None})\n        if not data:\n            self._data = PandasDataFrame()\n        if isinstance(data, dict):\n            self._data = PandasDataFrame(data)\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "core.py"], "context_start_lineno": 177, "lineno": 387, "function_name": "__init__", "line_no": 387}}
{"_id": "maxhumber_redframes/33", "text": "       |\n        | bar        | D       |\n        | baz        | !       |\n        | baz        | @       |\n        | baz        | #       |\n        | baz        | $       |\n        | jaz        | 0       |\n        | jaz        | 1       |\n        | jaz        | 2       |\n        | jaz        | 3       |\n\n        Multiple columns:\n\n        ```python\n        df.gather([\"foo\", \"bar\"], into=(\"var\", \"val\"))\n        ```\n        | baz   |   jaz | var   | val   |\n        |:------|------:|:------|:------|\n        | !     |     0 | foo   | 1     |\n        | @     |     1 | foo   | 2     |\n        | #     |     2 | foo   | 1     |\n        | $     |     3 | foo   | 2     |\n        | !     |     0 | bar   | A     |\n        | @     |     1 | bar   | B     |\n        | #     |     2 | bar   | C     |\n        | $     |     3 | bar   | D     |\n\n        All columns beside:\n\n        ```python\n        df.group([\"foo\", \"bar\"]).gather(into=(\"variable\", \"value\"))\n        ```\n        |   foo | bar   | variable   | value   |\n        |------:|:------|:-----------|:--------|\n        |     1 | A     | baz        | !       |\n        |     2 | B     | baz        | @       |\n        |     1 | C     | baz        | #       |\n        |     2 | D     | baz        | $       |\n        |     1 | A     | jaz        | 0       |\n        |     2 | B     | jaz        | 1       |\n        |     1 | C     | jaz        | 2       |\n        |     2 | D     | jaz        | 3       |\n        \"\"\"\n        return _wrap(gather(self._data, columns, beside, into))\n\n    def pack(self, column: Column, sep: str) -> DataFrame:\n        \"\"\"Collate and concatenate row values for a target column (opposite of unpack)\n\n        Examples:\n\n        ```python\n        df = rf.DataFrame({\n            \"foo\": [\"A\", \"A\", \"B\", \"A\", \"B\", \"C\"],\n            \"bar\": [1, 2, 3, 4, 5, 6]\n        })\n        ```\n        | foo   |   bar |\n        |:------|------:|\n        | A     |     1 |\n        | A     |     2 |\n        | B     |     3 |\n        | A     |     4 |\n        | B     |     5 |\n        | C     |     6 |\n\n        Pack all rows:\n\n        ```python\n        df.pack(\"foo\", sep=\"+\")\n        ```\n        | foo         |\n        |:------------|\n        | A+A+B+A+B+C |\n\n        Pack rows by Group:\n\n        ```python\n        df.group(\"foo\").pack(\"bar\", sep=\"|\")\n        ```\n        | foo   | bar   |\n        |:------|:------|\n        | A     | 1|2|4 |\n        | B     | 3|5   |\n        | C     | 6     |\n        \"\"\"\n        return _wrap(pack(self._data, column, sep))\n\n    def rank(\n        self,\n        column: Column,\n        into: Column,\n        descending: bool = False,\n    ) -> DataFrame:\n        \"\"\"Rank order values in a column\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [2, 3, 3, 99, 1000, 1, -6, 4]})\n        ```\n        |   foo |\n        |------:|\n        |     2 |\n        |     3 |\n        |     3 |\n        |    99 |\n        |  1000 |\n        |     1 |\n        |    -6 |\n        |     4 |\n\n        ```python\n        df.rank(\"foo\", into=\"rank\", descending=True)\n        ```\n        |   foo |   rank |\n        |------:|-------:|\n        |     2 |      5 |\n        |     3 |      4 |\n        |     3 |      4 |\n        |    99 |      2 |\n        |  1000 |      1 |\n        |     1 |      6 |\n        |    -6 |      7 |\n        |     4 |      3 |\n        \"\"\"\n        return _wrap(rank(self._data, column, into, descending))\n\n    def rollup(self, over: dict[Column, tuple[Column, Func]]) -> DataFrame:\n        \"\"\"Apply summary functions and/or statistics to target columns\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2, 3, 4, 5], \"bar\": [99, 100, 1, -5, 2]})\n        ```\n        |   foo |   bar |\n        |------:|------:|\n        |     1 |    99 |\n        |     2 |   100 |\n        |     3 |     1 |\n        |     4 |    -5 |\n        |     5 |     2 |\n\n        ```python\n        df.rollup({\n            \"fcount\": (\"foo\", rf.stat.count),\n            \"fmean\": (\"foo\", rf.stat.mean),\n            \"fsum\": (\"foo\", rf.stat.sum),\n            \"fmax\": (\"foo\", rf.stat.max),\n            \"bmedian\": (\"bar\", rf.stat.median),\n            \"bmin\": (\"bar\", rf.stat.min),\n            \"bstd\": (\"bar\", rf.stat.std)\n        })\n        ```\n        |   fcount |   fmean |   fsum |   fmax |   bmedian |   bmin |   bstd |\n        |---------:|--------:|-------:|-------:|----------:|-------:|-------:|\n        |        5 |       3 |     15 |      5 |         2 |     -5 |  54.93 |\n        \"\"\"\n        return _wrap(rollup(self._data, over))\n\n    def summarize(self, over: dict[Column, tuple[Column, Func]]) -> DataFrame:\n        message = \"Marked for removal, please use `rollup` instead\"\n        warnings.warn(message, FutureWarning)\n        return self.rollup(over)\n\n\nclass GroupedFrame(_CommonMixin):\n    \"\"\"GroupedFrame compatible with: `accumulate`, `gather`, `pack`, `rank`, `rollup`, `take`\"\"\"\n\n    def __repr__(self) -> str:\n        return self._data.obj.__repr__()  # type: ignore\n\n    def _repr_html_(self) -> str:\n        return self._data.obj.to_html(index=True)  # type: ignore\n\n\nclass DataFrame(_CommonMixin, _InterchangeMixin):\n    def __init__(self, data: dict[Column, Values] | None = None) -> None:\n        \"\"\"Initialize a DataFrame with a standard dictionary\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        ```\n        |   foo | bar   |\n        |------:|:------|\n        |     1 | A     |\n        |     2 | B     |\n        \"\"\"\n        _check_type(data, {dict, None})\n        if not data:\n            self._data = PandasDataFrame()\n        if isinstance(data, dict):\n            self._data = PandasDataFrame(data)\n\n    def __eq__(self, rhs: Any) -> bool:\n        \"\"\"Check if two DataFrames are equal to each other\n\n        Example:\n\n        ```python\n        adf = rf.DataFrame({\"foo\": [1]})\n        bdf = rf.DataFrame({\"bar\": [1]})\n        cdf = rf.DataFrame({\"foo\": [1]})\n        print(adf == bdf)\n        print(adf == cdf)\n        # False\n        # True\n        ```\n        \"\"\"", "metadata": {"task_id": "maxhumber_redframes/33", "ground_truth": "        if not isinstance(rhs, DataFrame):\n            return False\n        return self._data.equals(rhs._data)\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "core.py"], "context_start_lineno": 197, "lineno": 408, "function_name": "__eq__", "line_no": 408}}
{"_id": "maxhumber_redframes/34", "text": "group([\"foo\", \"bar\"]).gather(into=(\"variable\", \"value\"))\n        ```\n        |   foo | bar   | variable   | value   |\n        |------:|:------|:-----------|:--------|\n        |     1 | A     | baz        | !       |\n        |     2 | B     | baz        | @       |\n        |     1 | C     | baz        | #       |\n        |     2 | D     | baz        | $       |\n        |     1 | A     | jaz        | 0       |\n        |     2 | B     | jaz        | 1       |\n        |     1 | C     | jaz        | 2       |\n        |     2 | D     | jaz        | 3       |\n        \"\"\"\n        return _wrap(gather(self._data, columns, beside, into))\n\n    def pack(self, column: Column, sep: str) -> DataFrame:\n        \"\"\"Collate and concatenate row values for a target column (opposite of unpack)\n\n        Examples:\n\n        ```python\n        df = rf.DataFrame({\n            \"foo\": [\"A\", \"A\", \"B\", \"A\", \"B\", \"C\"],\n            \"bar\": [1, 2, 3, 4, 5, 6]\n        })\n        ```\n        | foo   |   bar |\n        |:------|------:|\n        | A     |     1 |\n        | A     |     2 |\n        | B     |     3 |\n        | A     |     4 |\n        | B     |     5 |\n        | C     |     6 |\n\n        Pack all rows:\n\n        ```python\n        df.pack(\"foo\", sep=\"+\")\n        ```\n        | foo         |\n        |:------------|\n        | A+A+B+A+B+C |\n\n        Pack rows by Group:\n\n        ```python\n        df.group(\"foo\").pack(\"bar\", sep=\"|\")\n        ```\n        | foo   | bar   |\n        |:------|:------|\n        | A     | 1|2|4 |\n        | B     | 3|5   |\n        | C     | 6     |\n        \"\"\"\n        return _wrap(pack(self._data, column, sep))\n\n    def rank(\n        self,\n        column: Column,\n        into: Column,\n        descending: bool = False,\n    ) -> DataFrame:\n        \"\"\"Rank order values in a column\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [2, 3, 3, 99, 1000, 1, -6, 4]})\n        ```\n        |   foo |\n        |------:|\n        |     2 |\n        |     3 |\n        |     3 |\n        |    99 |\n        |  1000 |\n        |     1 |\n        |    -6 |\n        |     4 |\n\n        ```python\n        df.rank(\"foo\", into=\"rank\", descending=True)\n        ```\n        |   foo |   rank |\n        |------:|-------:|\n        |     2 |      5 |\n        |     3 |      4 |\n        |     3 |      4 |\n        |    99 |      2 |\n        |  1000 |      1 |\n        |     1 |      6 |\n        |    -6 |      7 |\n        |     4 |      3 |\n        \"\"\"\n        return _wrap(rank(self._data, column, into, descending))\n\n    def rollup(self, over: dict[Column, tuple[Column, Func]]) -> DataFrame:\n        \"\"\"Apply summary functions and/or statistics to target columns\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2, 3, 4, 5], \"bar\": [99, 100, 1, -5, 2]})\n        ```\n        |   foo |   bar |\n        |------:|------:|\n        |     1 |    99 |\n        |     2 |   100 |\n        |     3 |     1 |\n        |     4 |    -5 |\n        |     5 |     2 |\n\n        ```python\n        df.rollup({\n            \"fcount\": (\"foo\", rf.stat.count),\n            \"fmean\": (\"foo\", rf.stat.mean),\n            \"fsum\": (\"foo\", rf.stat.sum),\n            \"fmax\": (\"foo\", rf.stat.max),\n            \"bmedian\": (\"bar\", rf.stat.median),\n            \"bmin\": (\"bar\", rf.stat.min),\n            \"bstd\": (\"bar\", rf.stat.std)\n        })\n        ```\n        |   fcount |   fmean |   fsum |   fmax |   bmedian |   bmin |   bstd |\n        |---------:|--------:|-------:|-------:|----------:|-------:|-------:|\n        |        5 |       3 |     15 |      5 |         2 |     -5 |  54.93 |\n        \"\"\"\n        return _wrap(rollup(self._data, over))\n\n    def summarize(self, over: dict[Column, tuple[Column, Func]]) -> DataFrame:\n        message = \"Marked for removal, please use `rollup` instead\"\n        warnings.warn(message, FutureWarning)\n        return self.rollup(over)\n\n\nclass GroupedFrame(_CommonMixin):\n    \"\"\"GroupedFrame compatible with: `accumulate`, `gather`, `pack`, `rank`, `rollup`, `take`\"\"\"\n\n    def __repr__(self) -> str:\n        return self._data.obj.__repr__()  # type: ignore\n\n    def _repr_html_(self) -> str:\n        return self._data.obj.to_html(index=True)  # type: ignore\n\n\nclass DataFrame(_CommonMixin, _InterchangeMixin):\n    def __init__(self, data: dict[Column, Values] | None = None) -> None:\n        \"\"\"Initialize a DataFrame with a standard dictionary\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        ```\n        |   foo | bar   |\n        |------:|:------|\n        |     1 | A     |\n        |     2 | B     |\n        \"\"\"\n        _check_type(data, {dict, None})\n        if not data:\n            self._data = PandasDataFrame()\n        if isinstance(data, dict):\n            self._data = PandasDataFrame(data)\n\n    def __eq__(self, rhs: Any) -> bool:\n        \"\"\"Check if two DataFrames are equal to each other\n\n        Example:\n\n        ```python\n        adf = rf.DataFrame({\"foo\": [1]})\n        bdf = rf.DataFrame({\"bar\": [1]})\n        cdf = rf.DataFrame({\"foo\": [1]})\n        print(adf == bdf)\n        print(adf == cdf)\n        # False\n        # True\n        ```\n        \"\"\"\n        if not isinstance(rhs, DataFrame):\n            return False\n        return self._data.equals(rhs._data)\n\n    def __getitem__(self, key: Column) -> Values:\n        \"\"\"Retrive values (as a python list) from a specified column\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        df[\"foo\"]\n        # [1, 2]\n        ```\n        \"\"\"\n        return list(self._data[key])\n\n    def __repr__(self) -> str:\n        return self._data.__repr__()\n\n    def _repr_html_(self) -> str:\n        return self._data.to_html(index=True)\n\n    def __str__(self) -> str:\n        \"\"\"Return string constructor (for copy-and-pasting)\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        str(df)\n        # \"rf.DataFrame({'foo': [1, 2], 'bar': ['A', 'B']})\"\n        ```\n        \"\"\"", "metadata": {"task_id": "maxhumber_redframes/34", "ground_truth": "        data = self._data.to_dict(orient=\"list\")\n        string = pprint.pformat(data, indent=4, sort_dicts=False, compact=True)\n        if \"\\n\" in string:\n            string = \" \" + string[1:-1]\n            string = f\"rf.DataFrame({{\\n{string}\\n}})\"\n        else:\n            string = f\"rf.DataFrame({string})\"\n        return string\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "core.py"], "context_start_lineno": 227, "lineno": 442, "function_name": "__str__", "line_no": 442}}
{"_id": "maxhumber_redframes/35", "text": ":------|:------|\n        | A     | 1|2|4 |\n        | B     | 3|5   |\n        | C     | 6     |\n        \"\"\"\n        return _wrap(pack(self._data, column, sep))\n\n    def rank(\n        self,\n        column: Column,\n        into: Column,\n        descending: bool = False,\n    ) -> DataFrame:\n        \"\"\"Rank order values in a column\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [2, 3, 3, 99, 1000, 1, -6, 4]})\n        ```\n        |   foo |\n        |------:|\n        |     2 |\n        |     3 |\n        |     3 |\n        |    99 |\n        |  1000 |\n        |     1 |\n        |    -6 |\n        |     4 |\n\n        ```python\n        df.rank(\"foo\", into=\"rank\", descending=True)\n        ```\n        |   foo |   rank |\n        |------:|-------:|\n        |     2 |      5 |\n        |     3 |      4 |\n        |     3 |      4 |\n        |    99 |      2 |\n        |  1000 |      1 |\n        |     1 |      6 |\n        |    -6 |      7 |\n        |     4 |      3 |\n        \"\"\"\n        return _wrap(rank(self._data, column, into, descending))\n\n    def rollup(self, over: dict[Column, tuple[Column, Func]]) -> DataFrame:\n        \"\"\"Apply summary functions and/or statistics to target columns\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2, 3, 4, 5], \"bar\": [99, 100, 1, -5, 2]})\n        ```\n        |   foo |   bar |\n        |------:|------:|\n        |     1 |    99 |\n        |     2 |   100 |\n        |     3 |     1 |\n        |     4 |    -5 |\n        |     5 |     2 |\n\n        ```python\n        df.rollup({\n            \"fcount\": (\"foo\", rf.stat.count),\n            \"fmean\": (\"foo\", rf.stat.mean),\n            \"fsum\": (\"foo\", rf.stat.sum),\n            \"fmax\": (\"foo\", rf.stat.max),\n            \"bmedian\": (\"bar\", rf.stat.median),\n            \"bmin\": (\"bar\", rf.stat.min),\n            \"bstd\": (\"bar\", rf.stat.std)\n        })\n        ```\n        |   fcount |   fmean |   fsum |   fmax |   bmedian |   bmin |   bstd |\n        |---------:|--------:|-------:|-------:|----------:|-------:|-------:|\n        |        5 |       3 |     15 |      5 |         2 |     -5 |  54.93 |\n        \"\"\"\n        return _wrap(rollup(self._data, over))\n\n    def summarize(self, over: dict[Column, tuple[Column, Func]]) -> DataFrame:\n        message = \"Marked for removal, please use `rollup` instead\"\n        warnings.warn(message, FutureWarning)\n        return self.rollup(over)\n\n\nclass GroupedFrame(_CommonMixin):\n    \"\"\"GroupedFrame compatible with: `accumulate`, `gather`, `pack`, `rank`, `rollup`, `take`\"\"\"\n\n    def __repr__(self) -> str:\n        return self._data.obj.__repr__()  # type: ignore\n\n    def _repr_html_(self) -> str:\n        return self._data.obj.to_html(index=True)  # type: ignore\n\n\nclass DataFrame(_CommonMixin, _InterchangeMixin):\n    def __init__(self, data: dict[Column, Values] | None = None) -> None:\n        \"\"\"Initialize a DataFrame with a standard dictionary\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        ```\n        |   foo | bar   |\n        |------:|:------|\n        |     1 | A     |\n        |     2 | B     |\n        \"\"\"\n        _check_type(data, {dict, None})\n        if not data:\n            self._data = PandasDataFrame()\n        if isinstance(data, dict):\n            self._data = PandasDataFrame(data)\n\n    def __eq__(self, rhs: Any) -> bool:\n        \"\"\"Check if two DataFrames are equal to each other\n\n        Example:\n\n        ```python\n        adf = rf.DataFrame({\"foo\": [1]})\n        bdf = rf.DataFrame({\"bar\": [1]})\n        cdf = rf.DataFrame({\"foo\": [1]})\n        print(adf == bdf)\n        print(adf == cdf)\n        # False\n        # True\n        ```\n        \"\"\"\n        if not isinstance(rhs, DataFrame):\n            return False\n        return self._data.equals(rhs._data)\n\n    def __getitem__(self, key: Column) -> Values:\n        \"\"\"Retrive values (as a python list) from a specified column\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        df[\"foo\"]\n        # [1, 2]\n        ```\n        \"\"\"\n        return list(self._data[key])\n\n    def __repr__(self) -> str:\n        return self._data.__repr__()\n\n    def _repr_html_(self) -> str:\n        return self._data.to_html(index=True)\n\n    def __str__(self) -> str:\n        \"\"\"Return string constructor (for copy-and-pasting)\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        str(df)\n        # \"rf.DataFrame({'foo': [1, 2], 'bar': ['A', 'B']})\"\n        ```\n        \"\"\"\n        data = self._data.to_dict(orient=\"list\")\n        string = pprint.pformat(data, indent=4, sort_dicts=False, compact=True)\n        if \"\\n\" in string:\n            string = \" \" + string[1:-1]\n            string = f\"rf.DataFrame({{\\n{string}\\n}})\"\n        else:\n            string = f\"rf.DataFrame({string})\"\n        return string\n\n    @property\n    def columns(self) -> Columns:\n        \"\"\"Inspect column keys (names)\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"], \"baz\": [True, False]})\n        df.columns\n        # ['foo', 'bar', 'baz']\n        ```\n        \"\"\"\n        return list(self._data.columns)\n\n    @property\n    def dimensions(self) -> dict[str, int]:\n        \"\"\"Inspect DataFrame shape\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": range(10), \"bar\": range(10, 20)})\n        df.dimensions\n        # {'rows': 10, 'columns': 2}\n        ```\n        \"\"\"\n        return dict(zip([\"rows\", \"columns\"], self._data.shape))\n\n    @property\n    def empty(self) -> bool:\n        \"\"\"Inspect if DataFrame is \"empty\"\n\n        Example:\n\n        ```python\n        df = rf.DataFrame()\n        df.empty\n        # True\n        ```\n        \"\"\"\n        return self._data.empty\n\n    @property\n    def memory(self) -> str:\n        \"\"\"Interrogate DataFrame (deep) memory usage\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2, 3], \"bar\": [\"A\", \"B\", \"C\"]})\n        df.memory\n        # '326B'\n        ```\n        \"\"\"", "metadata": {"task_id": "maxhumber_redframes/35", "ground_truth": "        size = self._data.memory_usage(deep=True).sum()\n        power_labels = {40: \"TB\", 30: \"GB\", 20: \"MB\", 10: \"KB\"}\n        for power, label in power_labels.items():\n            if size >= (2**power):\n                approx_size = size // 2**power\n                return f\"{approx_size} {label}\"\n        return f\"{size} B\"\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "core.py"], "context_start_lineno": 277, "lineno": 505, "function_name": "memory", "line_no": 505}}
{"_id": "maxhumber_redframes/36", "text": "\n\n        ```python\n        df.rank(\"foo\", into=\"rank\", descending=True)\n        ```\n        |   foo |   rank |\n        |------:|-------:|\n        |     2 |      5 |\n        |     3 |      4 |\n        |     3 |      4 |\n        |    99 |      2 |\n        |  1000 |      1 |\n        |     1 |      6 |\n        |    -6 |      7 |\n        |     4 |      3 |\n        \"\"\"\n        return _wrap(rank(self._data, column, into, descending))\n\n    def rollup(self, over: dict[Column, tuple[Column, Func]]) -> DataFrame:\n        \"\"\"Apply summary functions and/or statistics to target columns\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2, 3, 4, 5], \"bar\": [99, 100, 1, -5, 2]})\n        ```\n        |   foo |   bar |\n        |------:|------:|\n        |     1 |    99 |\n        |     2 |   100 |\n        |     3 |     1 |\n        |     4 |    -5 |\n        |     5 |     2 |\n\n        ```python\n        df.rollup({\n            \"fcount\": (\"foo\", rf.stat.count),\n            \"fmean\": (\"foo\", rf.stat.mean),\n            \"fsum\": (\"foo\", rf.stat.sum),\n            \"fmax\": (\"foo\", rf.stat.max),\n            \"bmedian\": (\"bar\", rf.stat.median),\n            \"bmin\": (\"bar\", rf.stat.min),\n            \"bstd\": (\"bar\", rf.stat.std)\n        })\n        ```\n        |   fcount |   fmean |   fsum |   fmax |   bmedian |   bmin |   bstd |\n        |---------:|--------:|-------:|-------:|----------:|-------:|-------:|\n        |        5 |       3 |     15 |      5 |         2 |     -5 |  54.93 |\n        \"\"\"\n        return _wrap(rollup(self._data, over))\n\n    def summarize(self, over: dict[Column, tuple[Column, Func]]) -> DataFrame:\n        message = \"Marked for removal, please use `rollup` instead\"\n        warnings.warn(message, FutureWarning)\n        return self.rollup(over)\n\n\nclass GroupedFrame(_CommonMixin):\n    \"\"\"GroupedFrame compatible with: `accumulate`, `gather`, `pack`, `rank`, `rollup`, `take`\"\"\"\n\n    def __repr__(self) -> str:\n        return self._data.obj.__repr__()  # type: ignore\n\n    def _repr_html_(self) -> str:\n        return self._data.obj.to_html(index=True)  # type: ignore\n\n\nclass DataFrame(_CommonMixin, _InterchangeMixin):\n    def __init__(self, data: dict[Column, Values] | None = None) -> None:\n        \"\"\"Initialize a DataFrame with a standard dictionary\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        ```\n        |   foo | bar   |\n        |------:|:------|\n        |     1 | A     |\n        |     2 | B     |\n        \"\"\"\n        _check_type(data, {dict, None})\n        if not data:\n            self._data = PandasDataFrame()\n        if isinstance(data, dict):\n            self._data = PandasDataFrame(data)\n\n    def __eq__(self, rhs: Any) -> bool:\n        \"\"\"Check if two DataFrames are equal to each other\n\n        Example:\n\n        ```python\n        adf = rf.DataFrame({\"foo\": [1]})\n        bdf = rf.DataFrame({\"bar\": [1]})\n        cdf = rf.DataFrame({\"foo\": [1]})\n        print(adf == bdf)\n        print(adf == cdf)\n        # False\n        # True\n        ```\n        \"\"\"\n        if not isinstance(rhs, DataFrame):\n            return False\n        return self._data.equals(rhs._data)\n\n    def __getitem__(self, key: Column) -> Values:\n        \"\"\"Retrive values (as a python list) from a specified column\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        df[\"foo\"]\n        # [1, 2]\n        ```\n        \"\"\"\n        return list(self._data[key])\n\n    def __repr__(self) -> str:\n        return self._data.__repr__()\n\n    def _repr_html_(self) -> str:\n        return self._data.to_html(index=True)\n\n    def __str__(self) -> str:\n        \"\"\"Return string constructor (for copy-and-pasting)\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        str(df)\n        # \"rf.DataFrame({'foo': [1, 2], 'bar': ['A', 'B']})\"\n        ```\n        \"\"\"\n        data = self._data.to_dict(orient=\"list\")\n        string = pprint.pformat(data, indent=4, sort_dicts=False, compact=True)\n        if \"\\n\" in string:\n            string = \" \" + string[1:-1]\n            string = f\"rf.DataFrame({{\\n{string}\\n}})\"\n        else:\n            string = f\"rf.DataFrame({string})\"\n        return string\n\n    @property\n    def columns(self) -> Columns:\n        \"\"\"Inspect column keys (names)\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"], \"baz\": [True, False]})\n        df.columns\n        # ['foo', 'bar', 'baz']\n        ```\n        \"\"\"\n        return list(self._data.columns)\n\n    @property\n    def dimensions(self) -> dict[str, int]:\n        \"\"\"Inspect DataFrame shape\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": range(10), \"bar\": range(10, 20)})\n        df.dimensions\n        # {'rows': 10, 'columns': 2}\n        ```\n        \"\"\"\n        return dict(zip([\"rows\", \"columns\"], self._data.shape))\n\n    @property\n    def empty(self) -> bool:\n        \"\"\"Inspect if DataFrame is \"empty\"\n\n        Example:\n\n        ```python\n        df = rf.DataFrame()\n        df.empty\n        # True\n        ```\n        \"\"\"\n        return self._data.empty\n\n    @property\n    def memory(self) -> str:\n        \"\"\"Interrogate DataFrame (deep) memory usage\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2, 3], \"bar\": [\"A\", \"B\", \"C\"]})\n        df.memory\n        # '326B'\n        ```\n        \"\"\"\n        size = self._data.memory_usage(deep=True).sum()\n        power_labels = {40: \"TB\", 30: \"GB\", 20: \"MB\", 10: \"KB\"}\n        for power, label in power_labels.items():\n            if size >= (2**power):\n                approx_size = size // 2**power\n                return f\"{approx_size} {label}\"\n        return f\"{size} B\"\n\n    @property\n    def types(self) -> dict[Column, type]:\n        \"\"\"Inspect column types\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"], \"baz\": [True, False]})\n        df.types\n        # {'foo': int, 'bar': object, 'baz': bool}\n        ```\n        \"\"\"", "metadata": {"task_id": "maxhumber_redframes/36", "ground_truth": "        numpy_types = {\n            NumpyType(\"O\"): object,\n            NumpyType(\"int64\"): int,\n            NumpyType(\"float64\"): float,\n            NumpyType(\"bool\"): bool,\n            NumpyType(\"datetime64\"): DateTime,\n        }\n        raw_types = dict(self._data.dtypes)\n        clean_types = {}\n        for column in self.columns:\n            current = raw_types[column]\n            clean = numpy_types.get(current, current)  # type: ignore\n            clean_types[column] = clean\n        return clean_types\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "core.py"], "context_start_lineno": 306, "lineno": 525, "function_name": "types", "line_no": 525}}
{"_id": "maxhumber_redframes/37", "text": " -> str:\n        \"\"\"Return string constructor (for copy-and-pasting)\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        str(df)\n        # \"rf.DataFrame({'foo': [1, 2], 'bar': ['A', 'B']})\"\n        ```\n        \"\"\"\n        data = self._data.to_dict(orient=\"list\")\n        string = pprint.pformat(data, indent=4, sort_dicts=False, compact=True)\n        if \"\\n\" in string:\n            string = \" \" + string[1:-1]\n            string = f\"rf.DataFrame({{\\n{string}\\n}})\"\n        else:\n            string = f\"rf.DataFrame({string})\"\n        return string\n\n    @property\n    def columns(self) -> Columns:\n        \"\"\"Inspect column keys (names)\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"], \"baz\": [True, False]})\n        df.columns\n        # ['foo', 'bar', 'baz']\n        ```\n        \"\"\"\n        return list(self._data.columns)\n\n    @property\n    def dimensions(self) -> dict[str, int]:\n        \"\"\"Inspect DataFrame shape\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": range(10), \"bar\": range(10, 20)})\n        df.dimensions\n        # {'rows': 10, 'columns': 2}\n        ```\n        \"\"\"\n        return dict(zip([\"rows\", \"columns\"], self._data.shape))\n\n    @property\n    def empty(self) -> bool:\n        \"\"\"Inspect if DataFrame is \"empty\"\n\n        Example:\n\n        ```python\n        df = rf.DataFrame()\n        df.empty\n        # True\n        ```\n        \"\"\"\n        return self._data.empty\n\n    @property\n    def memory(self) -> str:\n        \"\"\"Interrogate DataFrame (deep) memory usage\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2, 3], \"bar\": [\"A\", \"B\", \"C\"]})\n        df.memory\n        # '326B'\n        ```\n        \"\"\"\n        size = self._data.memory_usage(deep=True).sum()\n        power_labels = {40: \"TB\", 30: \"GB\", 20: \"MB\", 10: \"KB\"}\n        for power, label in power_labels.items():\n            if size >= (2**power):\n                approx_size = size // 2**power\n                return f\"{approx_size} {label}\"\n        return f\"{size} B\"\n\n    @property\n    def types(self) -> dict[Column, type]:\n        \"\"\"Inspect column types\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"], \"baz\": [True, False]})\n        df.types\n        # {'foo': int, 'bar': object, 'baz': bool}\n        ```\n        \"\"\"\n        numpy_types = {\n            NumpyType(\"O\"): object,\n            NumpyType(\"int64\"): int,\n            NumpyType(\"float64\"): float,\n            NumpyType(\"bool\"): bool,\n            NumpyType(\"datetime64\"): DateTime,\n        }\n        raw_types = dict(self._data.dtypes)\n        clean_types = {}\n        for column in self.columns:\n            current = raw_types[column]\n            clean = numpy_types.get(current, current)  # type: ignore\n            clean_types[column] = clean\n        return clean_types\n\n    def append(self, other: DataFrame) -> DataFrame:\n        \"\"\"Append rows from another DataFrame\n\n        Example:\n\n        ```python\n        df1 = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        ```\n        |   foo | bar   |\n        |------:|:------|\n        |     1 | A     |\n        |     2 | B     |\n\n        ```python\n        df2 = rf.DataFrame({\"bar\": [\"C\", \"D\"], \"foo\": [3, 4], \"baz\": [\"$\", \"@\"]})\n        ```\n        | bar   |   foo | baz   |\n        |:------|------:|:------|\n        | C     |     3 | $     |\n        | D     |     4 | @     |\n\n        ```python\n        df1.append(df2)\n        ```\n        |   foo | bar   | baz   |\n        |------:|:------|:------|\n        |     1 | A     | nan   |\n        |     2 | B     | nan   |\n        |     3 | C     | $     |\n        |     4 | D     | @     |\n        \"\"\"\n        _check_type(other, DataFrame)\n        return _wrap(append(self._data, other._data))\n\n    def combine(\n        self, columns: Columns, into: Column, sep: str, drop: bool = True\n    ) -> DataFrame:\n        \"\"\"Combine multiple columns into a single column (opposite of `split`)\n\n        Example:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [1, 2], \"bar\": [\"A\", \"B\"]})\n        ```\n        |   foo | bar   |\n        |------:|:------|\n        |     1 | A     |\n        |     2 | B     |\n\n        ```python\n        df.combine([\"bar\", \"foo\"], into=\"baz\", sep=\"::\", drop=True)\n        ```\n        | baz   |\n        |:------|\n        | A::1  |\n        | B::2  |\n        \"\"\"\n        return _wrap(combine(self._data, columns, into, sep, drop))\n\n    def cross(\n        self, rhs: DataFrame | None = None, postfix: tuple[str, str] = (\"_lhs\", \"_rhs\")\n    ) -> DataFrame:\n        \"\"\"Cross join columns from another DataFrame\n\n        Examples:\n\n        ```python\n        df = rf.DataFrame({\"foo\": [\"a\", \"b\", \"c\"], \"bar\": [1, 2, 3]})\n        ```\n        | foo   |   bar |\n        |:------|------:|\n        | a     |     1 |\n        | b     |     2 |\n        | c     |     3 |\n\n        Self:\n\n        ```python\n        df.cross()\n        ```\n\n        | foo_lhs   |   bar_lhs | foo_rhs   |   bar_rhs |\n        |:----------|----------:|:----------|----------:|\n        | a         |         1 | a         |         1 |\n        | a         |         1 | b         |         2 |\n        | a         |         1 | c         |         3 |\n        | b         |         2 | a         |         1 |\n        | b         |         2 | b         |         2 |\n        | b         |         2 | c         |         3 |\n        | c         |         3 | a         |         1 |\n        | c         |         3 | b         |         2 |\n        | c         |         3 | c         |         3 |\n\n        Two DataFrames:\n\n        ```python\n        dfa = rf.DataFrame({\"foo\": [1, 2, 3]})\n        dfb = rf.DataFrame({\"bar\": [1, 2, 3]})\n        dfa.cross(dfb, postfix=(\"_a\", \"_b\"))\n        ```\n\n        |   foo |   bar |\n        |------:|------:|\n        |     1 |     1 |\n        |     1 |     2 |\n        |     1 |     3 |\n        |     2 |     1 |\n        |     2 |     2 |\n        |     2 |     3 |\n        |     3 |     1 |\n        |     3 |     2 |\n        |     3 |     3 |\n        \"\"\"", "metadata": {"task_id": "maxhumber_redframes/37", "ground_truth": "        rhs = self if (rhs == None) else rhs\n        _check_type(rhs, DataFrame)\n        return _wrap(cross(self._data, rhs._data, postfix))  # type: ignore\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "core.py"], "context_start_lineno": 431, "lineno": 653, "function_name": "cross", "line_no": 653}}
{"_id": "maxhumber_redframes/38", "text": "from __future__ import annotations\n\nfrom .types import (\n    Any,\n    Columns,\n    LazyColumns,\n    PandasDataFrame,\n    PandasIndex,\n    PandasRangeIndex,\n)\n\n\ndef _check_type(argument: Any, against: type | set[type | None]) -> None:", "metadata": {"task_id": "maxhumber_redframes/38", "ground_truth": "    if isinstance(against, set):\n        if len(against) == 0:\n            against = {against}  # type: ignore\n    if not isinstance(against, set):\n        against = {against}\n    optional = None in against\n    just_types = against.difference({None})\n    checks = [isinstance(argument, t) for t in just_types]  # type: ignore\n    if optional:\n        checks += [argument == None]\n    if not any(checks):\n        str_types = \" | \".join([t.__name__ for t in just_types])  # type: ignore\n        if optional:\n            str_types += \" | None\"\n        raise TypeError(f\"must be {str_types}\")\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "checks.py"], "context_start_lineno": 0, "lineno": 13, "function_name": "_check_type", "line_no": 13}}
{"_id": "maxhumber_redframes/39", "text": "from __future__ import annotations\n\nfrom .types import (\n    Any,\n    Columns,\n    LazyColumns,\n    PandasDataFrame,\n    PandasIndex,\n    PandasRangeIndex,\n)\n\n\ndef _check_type(argument: Any, against: type | set[type | None]) -> None:\n    if isinstance(against, set):\n        if len(against) == 0:\n            against = {against}  # type: ignore\n    if not isinstance(against, set):\n        against = {against}\n    optional = None in against\n    just_types = against.difference({None})\n    checks = [isinstance(argument, t) for t in just_types]  # type: ignore\n    if optional:\n        checks += [argument == None]\n    if not any(checks):\n        str_types = \" | \".join([t.__name__ for t in just_types])  # type: ignore\n        if optional:\n            str_types += \" | None\"\n        raise TypeError(f\"must be {str_types}\")\n\n\ndef _check_values(values: Any, type: type) -> None:\n    if not all(isinstance(value, type) for value in values):\n        raise TypeError(f\"must be {type.__name__}\")\n\n\ndef _check_keys(columns: LazyColumns | None, against: Columns | PandasIndex) -> None:", "metadata": {"task_id": "maxhumber_redframes/39", "ground_truth": "    if isinstance(columns, str):\n        columns = [columns]\n    columns = [] if (columns == None) else columns\n    bad_keys = set(columns).difference(against)  # type: ignore\n    if bad_keys:\n        if len(bad_keys) == 1:\n            raise KeyError(f\"invalid key {bad_keys}\")\n        else:\n            raise KeyError(f\"invalid keys {bad_keys}\")\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "checks.py"], "context_start_lineno": 0, "lineno": 36, "function_name": "_check_keys", "line_no": 36}}
{"_id": "maxhumber_redframes/40", "text": "from __future__ import annotations\n\nfrom .types import (\n    Any,\n    Columns,\n    LazyColumns,\n    PandasDataFrame,\n    PandasIndex,\n    PandasRangeIndex,\n)\n\n\ndef _check_type(argument: Any, against: type | set[type | None]) -> None:\n    if isinstance(against, set):\n        if len(against) == 0:\n            against = {against}  # type: ignore\n    if not isinstance(against, set):\n        against = {against}\n    optional = None in against\n    just_types = against.difference({None})\n    checks = [isinstance(argument, t) for t in just_types]  # type: ignore\n    if optional:\n        checks += [argument == None]\n    if not any(checks):\n        str_types = \" | \".join([t.__name__ for t in just_types])  # type: ignore\n        if optional:\n            str_types += \" | None\"\n        raise TypeError(f\"must be {str_types}\")\n\n\ndef _check_values(values: Any, type: type) -> None:\n    if not all(isinstance(value, type) for value in values):\n        raise TypeError(f\"must be {type.__name__}\")\n\n\ndef _check_keys(columns: LazyColumns | None, against: Columns | PandasIndex) -> None:\n    if isinstance(columns, str):\n        columns = [columns]\n    columns = [] if (columns == None) else columns\n    bad_keys = set(columns).difference(against)  # type: ignore\n    if bad_keys:\n        if len(bad_keys) == 1:\n            raise KeyError(f\"invalid key {bad_keys}\")\n        else:\n            raise KeyError(f\"invalid keys {bad_keys}\")\n\n\ndef _check_index(df: PandasDataFrame) -> None:", "metadata": {"task_id": "maxhumber_redframes/40", "ground_truth": "    if not (df.index.name == None):\n        raise IndexError(\"must be unnamed\")\n    if not isinstance(df.index, PandasRangeIndex):\n        raise IndexError(\"must be range\")\n    if not (df.index.start == 0):\n        raise IndexError(\"must start at 0\")\n    if not (df.index.step == 1):\n        raise IndexError(\"must step by 1\")\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "checks.py"], "context_start_lineno": 0, "lineno": 48, "function_name": "_check_index", "line_no": 48}}
{"_id": "maxhumber_redframes/41", "text": "from __future__ import annotations\n\nfrom .types import (\n    Any,\n    Columns,\n    LazyColumns,\n    PandasDataFrame,\n    PandasIndex,\n    PandasRangeIndex,\n)\n\n\ndef _check_type(argument: Any, against: type | set[type | None]) -> None:\n    if isinstance(against, set):\n        if len(against) == 0:\n            against = {against}  # type: ignore\n    if not isinstance(against, set):\n        against = {against}\n    optional = None in against\n    just_types = against.difference({None})\n    checks = [isinstance(argument, t) for t in just_types]  # type: ignore\n    if optional:\n        checks += [argument == None]\n    if not any(checks):\n        str_types = \" | \".join([t.__name__ for t in just_types])  # type: ignore\n        if optional:\n            str_types += \" | None\"\n        raise TypeError(f\"must be {str_types}\")\n\n\ndef _check_values(values: Any, type: type) -> None:\n    if not all(isinstance(value, type) for value in values):\n        raise TypeError(f\"must be {type.__name__}\")\n\n\ndef _check_keys(columns: LazyColumns | None, against: Columns | PandasIndex) -> None:\n    if isinstance(columns, str):\n        columns = [columns]\n    columns = [] if (columns == None) else columns\n    bad_keys = set(columns).difference(against)  # type: ignore\n    if bad_keys:\n        if len(bad_keys) == 1:\n            raise KeyError(f\"invalid key {bad_keys}\")\n        else:\n            raise KeyError(f\"invalid keys {bad_keys}\")\n\n\ndef _check_index(df: PandasDataFrame) -> None:\n    if not (df.index.name == None):\n        raise IndexError(\"must be unnamed\")\n    if not isinstance(df.index, PandasRangeIndex):\n        raise IndexError(\"must be range\")\n    if not (df.index.start == 0):\n        raise IndexError(\"must start at 0\")\n    if not (df.index.step == 1):\n        raise IndexError(\"must step by 1\")\n\n\ndef _check_columns(df: PandasDataFrame) -> None:", "metadata": {"task_id": "maxhumber_redframes/41", "ground_truth": "    if type(df.columns) != PandasIndex:\n        raise KeyError(\"must be flat\")\n    if df.columns.has_duplicates:\n        raise KeyError(\"must not contain duplicate keys\")\n", "fpath_tuple": ["maxhumber_redframes", "redframes", "checks.py"], "context_start_lineno": 0, "lineno": 59, "function_name": "_check_columns", "line_no": 59}}
